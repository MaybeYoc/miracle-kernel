# SPDX-License-Identifier: GPL-2.0
#
# General architecture dependent options
#

#
# Note: arch/$(SRCARCH)/Kconfig needs to be included first so that it can
# override the default values in this file.
#
source "arch/$(SRCARCH)/Kconfig"

menu "General architecture-dependent options"

config JUMP_LABEL
       bool "Optimize very unlikely/likely branches"
       depends on HAVE_ARCH_JUMP_LABEL
       depends on CC_HAS_ASM_GOTO
       help
         This option enables a transparent branch optimization that
	 makes certain almost-always-true or almost-always-false branch
	 conditions even cheaper to execute within the kernel.

	 Certain performance-sensitive kernel code, such as trace points,
	 scheduler functionality, networking code and KVM have such
	 branches and include support for this optimization technique.

         If it is detected that the compiler has support for "asm goto",
	 the kernel will compile such branches with just a nop
	 instruction. When the condition flag is toggled to true, the
	 nop will be converted to a jump instruction to execute the
	 conditional block of instructions.

	 This technique lowers overhead and stress on the branch prediction
	 of the processor and generally makes the kernel faster. The update
	 of the condition is slower, but those are always very rare.

	 ( On 32-bit x86, the necessary options added to the compiler
	   flags may increase the size of the kernel slightly. )

config STATIC_KEYS_SELFTEST
	bool "Static key selftest"
	depends on JUMP_LABEL
	help
	  Boot time self-test of the branch patching code.

config HAVE_64BIT_ALIGNED_ACCESS
	def_bool 64BIT && !HAVE_EFFICIENT_UNALIGNED_ACCESS
	help
	  Some architectures require 64 bit accesses to be 64 bit
	  aligned, which also requires structs containing 64 bit values
	  to be 64 bit aligned too. This includes some 32 bit
	  architectures which can do 64 bit accesses, as well as 64 bit
	  architectures without unaligned access.

	  This symbol should be selected by an architecture if 64 bit
	  accesses are required to be 64 bit aligned in this way even
	  though it is not a 64 bit architecture.

	  See Documentation/unaligned-memory-access.txt for more
	  information on the topic of unaligned memory accesses.

config HAVE_EFFICIENT_UNALIGNED_ACCESS
	bool
	help
	  Some architectures are unable to perform unaligned accesses
	  without the use of get_unaligned/put_unaligned. Others are
	  unable to perform such accesses efficiently (e.g. trap on
	  unaligned access and require fixing it up in the exception
	  handler.)

	  This symbol should be selected by an architecture if it can
	  perform unaligned accesses efficiently to allow different
	  code paths to be selected for these cases. Some network
	  drivers, for example, could opt to not fix up alignment
	  problems with received packets if doing so would not help
	  much.

	  See Documentation/unaligned-memory-access.txt for more
	  information on the topic of unaligned memory accesses.

config ARCH_USE_BUILTIN_BSWAP
       bool
       help
	 Modern versions of GCC (since 4.4) have builtin functions
	 for handling byte-swapping. Using these, instead of the old
	 inline assembler that the architecture code provides in the
	 __arch_bswapXX() macros, allows the compiler to see what's
	 happening and offers more opportunity for optimisation. In
	 particular, the compiler will be able to combine the byteswap
	 with a nearby load or store and use load-and-swap or
	 store-and-swap instructions if the architecture has them. It
	 should almost *never* result in code which is worse than the
	 hand-coded assembler in <asm/swab.h>.  But just in case it
	 does, the use of the builtins is optional.

	 Any architecture with load-and-swap or store-and-swap
	 instructions should set this. And it shouldn't hurt to set it
	 on architectures that don't have such instructions.

config HAVE_ARCH_VMAP_STACK
	def_bool n
	help
	  An arch should select this symbol if it can support kernel stacks
	  in vmalloc space.  This means:

	  - vmalloc space must be large enough to hold many kernel stacks.
	    This may rule out many 32-bit architectures.

	  - Stacks in vmalloc space need to work reliably.  For example, if
	    vmap page tables are created on demand, either this mechanism
	    needs to work while the stack points to a virtual address with
	    unpopulated page tables or arch code (switch_to() and switch_mm(),
	    most likely) needs to ensure that the stack's page table entries
	    are populated before running on a possibly unpopulated stack.

	  - If the stack overflows into a guard page, something reasonable
	    should happen.  The definition of "reasonable" is flexible, but
	    instantly rebooting without logging anything would be unfriendly.

config VMAP_STACK
	default y
	bool "Use a virtually-mapped stack"
	depends on HAVE_ARCH_VMAP_STACK
	---help---
	  Enable this if you want the use virtually-mapped kernel stacks
	  with guard pages.  This causes kernel stack overflows to be
	  caught immediately rather than causing difficult-to-diagnose
	  corruption.

	  This is presently incompatible with KASAN because KASAN expects
	  the stack to map directly to the KASAN shadow map using a formula
	  that is incorrect if the stack is in vmalloc space.

config HAVE_ARCH_JUMP_LABEL
	bool

config HAVE_ARCH_JUMP_LABEL_RELATIVE
	bool

config HAVE_STACKPROTECTOR
	bool
	help
	  An arch should select this symbol if:
	  - it has implemented a stack canary (e.g. __stack_chk_guard)

config CC_HAS_STACKPROTECTOR_NONE
	def_bool $(cc-option,-fno-stack-protector)

config STACKPROTECTOR
	bool "Stack Protector buffer overflow detection"
	depends on HAVE_STACKPROTECTOR
	depends on $(cc-option,-fstack-protector)
	default y
	help
	  This option turns on the "stack-protector" GCC feature. This
	  feature puts, at the beginning of functions, a canary value on
	  the stack just before the return address, and validates
	  the value just before actually returning.  Stack based buffer
	  overflows (that need to overwrite this return address) now also
	  overwrite the canary, which gets detected and the attack is then
	  neutralized via a kernel panic.

	  Functions will have the stack-protector canary logic added if they
	  have an 8-byte or larger character array on the stack.

	  This feature requires gcc version 4.2 or above, or a distribution
	  gcc with the feature backported ("-fstack-protector").

	  On an x86 "defconfig" build, this feature adds canary checks to
	  about 3% of all kernel functions, which increases kernel code size
	  by about 0.3%.

config STACKPROTECTOR_STRONG
	bool "Strong Stack Protector"
	depends on STACKPROTECTOR
	depends on $(cc-option,-fstack-protector-strong)
	default y
	help
	  Functions will have the stack-protector canary logic added in any
	  of the following conditions:

	  - local variable's address used as part of the right hand side of an
	    assignment or function argument
	  - local variable is an array (or union containing an array),
	    regardless of array type or length
	  - uses register local variables

	  This feature requires gcc version 4.9 or above, or a distribution
	  gcc with the feature backported ("-fstack-protector-strong").

	  On an x86 "defconfig" build, this feature adds canary checks to
	  about 20% of all kernel functions, which increases the kernel code
	  size by about 2%.

config ARCH_MMAP_RND_BITS_MIN
	int

config ARCH_MMAP_RND_BITS_MAX
	int

config HAVE_ALIGNED_STRUCT_PAGE
	bool
	help
	  This makes sure that struct pages are double word aligned and that
	  e.g. the SLUB allocator can perform double word atomic operations
	  on a struct page for better performance. However selecting this
	  might increase the size of a struct page by a word.

config HAVE_STACK_VALIDATION
	bool
	help
	  Architecture supports the 'objtool check' host tool command, which
	  performs compile-time stack metadata validation.

config HAVE_ARCH_COMPILER_H
	bool
	help
	  An architecture can select this if it provides an
	  asm/compiler.h header that should be included after
	  linux/compiler-*.h in order to override macro definitions that those
	  headers generally provide.

config HAVE_ARCH_PREL32_RELOCATIONS
	bool
	help
	  May be selected by an architecture if it supports place-relative
	  32-bit relocations, both in the toolchain and in the module loader,
	  in which case relative references can be used in special sections
	  for PCI fixup, initcalls etc which are only half the size on 64 bit
	  architectures, and don't require runtime relocation on relocatable
	  kernels.

source "scripts/gcc-plugins/Kconfig"

endmenu
